[
  {
    "objectID": "lectures/wyklad1.html",
    "href": "lectures/wyklad1.html",
    "title": "Wprowadzenie do obliczeÅ„ kwantowych",
    "section": "",
    "text": "Nature isnâ€™t classical, dammit, and if you want to make a simulation of Nature, youâ€™d better make it quantum mechanical, and by golly itâ€™s a wonderful problem because it doesnâ€™t look so easy.\nRichard Feynman\nCelem tego wykÅ‚adu jest zrozumienie, czym sÄ…:\nQuntum Machine Learning",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Wprowadzenie do obliczeÅ„ kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#uczenie-maszynowe",
    "href": "lectures/wyklad1.html#uczenie-maszynowe",
    "title": "Wprowadzenie do obliczeÅ„ kwantowych",
    "section": "Uczenie maszynowe",
    "text": "Uczenie maszynowe\nUczenie maszynowe (ale rÃ³wnieÅ¼ AI i uczenie gÅ‚Ä™bokie) to nauka i ,,sztukaâ€™â€™ opisujÄ…ca jak sprawiÄ‡ by komputery mogÅ‚y ,,uczyÄ‡ siÄ™â€™â€™ na podstawie danych, tak by rozwiÄ…zaÄ‡ problemy, ktÃ³rych typowe programowanie nie miaÅ‚oby sensu (lub byÅ‚oby zbyt skomplikowane).\n\nIn 1959, Arthur Samuel:\na field of study that gives computers the ability to learn without being explicitly programmed.\n\n\nDane\n\n\n\nModele\n\n\nUczenie nadzorowane (ang. supervised learning) - posiadajÄ…c oznaczone dane \\((x_i, y_i)\\) szukamy funkcji \\(f(x_i) = y_i\\) tak by uogÃ³lniÄ‡ jÄ… na nowe dane. Np. daÄ‡ kredyt, czy na obrazie jest kot albo pies itp.\nUczenie nienadzorowane (ang. unsupervised learning) - posiadajÄ…c dane \\((x_i)\\) szukamy ukrytych struktur w danych.\nUczenie przez wzmacnianie (ang. reinforcement learning) - agent uczy siÄ™ realizowaÄ‡ zadania w Å›rodowisku na podstawie nagrÃ³d i kar.\n\nJednym z podstawowych celÃ³w uczenia maszynowego (a takze i gÅ‚Ä™bokiego), jest przypisanie klasy (target, labels) dla nowych, nieoznakowanych danych.\nIstniejÄ… dwa gÅ‚Ã³wne typy dla tego zadania:\n\nRegresja â€“ przewidywanie wartoÅ›ci ciÄ…gÅ‚ej,\nklasyfikacja - przewidywanie wartoÅ›ci dyskretnej.\n\n\n\nFunkcja straty\nFunkcja straty mierzy jak przewidywania modelu sÄ… oddalone od rzeczywistych wartoÅ›ci.\n\nPomaga optymalizowaÄ‡ parametry modelu przez mechanizm propagacji wstecz\nPozwala na dopasowanie modelu do danych\nMniejsza wartoÅ›Ä‡ funkcji straty = lepsza jakoÅ›Ä‡ modelu.\n\n\n\n\n\nSieci Neuronowe\n\n\nModel z parametrami do trenowania \\(f(x;\\theta)= \\sigma(Wx+b)\\) gdzie \\(\\theta= \\{W, b\\}\\)\nFunkcja kosztu \\(C = \\sum_{i} ( f(x_i, \\theta)-y_i )^2\\)\nSpadek po gradiencie\n\noblicz gradient funkcji kosztu\nzaktualizuj parametry \\(\\theta^{t+1} = \\theta^{t} - \\eta \\nabla C\\)\n\n\n\nimport torch\nfrom torch.autograd import Variable\n\ndata = torch.tensor([(0. , 1.), (0.1 , 1.1), (0.2 , 1.2)])\n\ndef model(phi, x=None):\n    return x*phi\n\ndef loss(a, b):\n    return torch.abs(a-b) ** 2\n\ndef avg_loss(phi):\n    c = 0 \n    for x, y in data:\n        c += loss(model(phi, x=x), y)\n    return c\n\nphi_ = Variable(torch.tensor(0.1), requires_grad=True)\nopt = torch.optim.Adam([phi_],lr=0.2)\n\nfor i in range(5):\n    l = avg_loss(phi_)\n    print(f\"cost: {l}, for phi: {phi_}\")\n    l.backward()\n    opt.step()\n\ncost: 3.5805001258850098, for phi: 0.10000000149011612\ncost: 3.44450044631958, for phi: 0.29999998211860657\ncost: 3.3168272972106934, for phi: 0.49334585666656494\ncost: 3.1936793327331543, for phi: 0.6854467988014221\ncost: 3.073840856552124, for phi: 0.878169059753418\n\n\n\n\nObliczenia kwantowe opisujÄ… przetwarzenie informacji na urzÄ…dzeniach pracujÄ…cych zgodnie z zasadami mechaniki kwantowej.\n\nUwaga! klasyczne komputery (tranzystory) rÃ³wnieÅ¼ dziaÅ‚ajÄ… zgodnie z zasadami mechaniki kwantowej, ale wykonywane operacje opierajÄ… siÄ™ o logikÄ™ klasycznÄ….\n\nOba kierunki sÄ… istotne w procesie przetwarzania danych obecnie i w niedalekiej przyszÅ‚oÅ›ci. Dlatego naturalnym pytaniem jest jak je ze sobÄ… poÅ‚Ä…czyÄ‡?\nQML to realizowanie metod uczenia maszynowego, ktÃ³re mogÄ… byÄ‡ wykonywane na komputerach kwantowych.\nKwantowe uczenie maszynowe moÅ¼emy okreÅ›liÄ‡ jako uczenie maszynowe realizowane na komputerach kwantowych. Zasadniczym jest pytanie na ile i czy wogÃ³le komputery kwantowe mogÄ… poprawiÄ‡ jakoÅ›Ä‡ modeli uczenia maszynowego i czy pozwalajÄ… zrealizowaÄ‡ coÅ› wiÄ™cej niÅ¼ wykorzystanie klasycznych komputerÃ³w.\n\n\nHistoria MK\nPoczÄ…tek Mechaniki Kwantowej zwiÄ…zane sÄ… z pracami Maxa Plancka (1900) i Alberta Einsteina (1905), ktÃ³rzy wprowadzili pojÄ™cie kwantu - czyli najmniejszej porcji energii. Dalszy rozwÃ³j Mechaniki Kwantowej zwiÄ…zany jest z badaniami takich naukowcÃ³w jak Niels Bohr, Erwin SchrÃ¶dinger, Louis de Broglie, Heisenberg, Dirac, Feynman i wielu innych. PozostaÅ‚e informacje moÅ¼esz znaleÅºÄ‡ w artykule o obliczeniach kwantowych\n\nInformatykÃ³w (najczÄ™Å›ciej) nie interesuje, w jaki sposÃ³b wÅ‚aÅ›ciwoÅ›ci fizyczne ukÅ‚adÃ³w sÄ… wykorzystywane do przechowywania informacji w komputerze klasycznym. Podobnie, nie muszÄ… siÄ™ zastanawiaÄ‡ nad fizycznym mechanizmem, za pomocÄ… ktÃ³rego informacja kwantowa jest realizowana w komputerze kwantowym. Czy prowadzÄ…c samochÃ³d zastanawiasz siÄ™, jak dokÅ‚adnie dziaÅ‚ajÄ… wszystkie jego czÄ™Å›ci? A piszÄ…c kod modelu, zastanawiasz siÄ™, jak zostaÅ‚ on zaimplementowany w bibliotece?â€ Informatycy czÄ™sto nie muszÄ… zagÅ‚Ä™biaÄ‡ siÄ™ w szczegÃ³Å‚y fizycznej realizacji, skupiajÄ…c siÄ™ za to na wydajnym wykorzystaniu technologii komputerowych.\n\n\n\nHistoria obliczeÅ„ kwantowych\n\n1936 Alan Turing opublikowaÅ‚ pracÄ™ On Computable Numbers, ktÃ³ra stanowiÅ‚a istotny krok w kierunku teoretycznych podstaw obliczeÅ„ (Hilbert Problems) - universal computing machine local\n1976 Roman S. Ingarden - Quantum Information Theory Roman S. Ingarden wprowadziÅ‚ pojÄ™cie teorii informacji kwantowej, co miaÅ‚o kluczowe znaczenie dla rozwoju komputerÃ³w kwantowych.\n1980 Paul Benioff - Paul Benioff przedstawiÅ‚ teoretycznÄ… koncepcjÄ™ komputerÃ³w kwantowych jako fizycznych systemÃ³w, otwierajÄ…c drzwi do praktycznych implementacji.\n1981 Richard Feynman - zwrÃ³ciÅ‚ uwagÄ™ na to, Å¼e klasyczne komputery nie sÄ… w stanie efektywnie symulowaÄ‡ procesÃ³w kwantowych.\n1985 David Deutsch opracowaÅ‚ pierwszy opis kwantowej maszyny Turinga i algorytmÃ³w przeznaczonych do uruchamiania na komputerach kwantowych, w tym bramek kwantowych.\n1994 Peter Shor opracowaÅ‚ algorytm faktoryzacji liczb w czasie wielomianowym, co miaÅ‚o znaczenie dla kryptografii i bezpieczeÅ„stwa informacji.\n1996 Lov Grover - Lov Grover stworzyÅ‚ algorytm Groverâ€™a, ktÃ³ry okazaÅ‚ siÄ™ wyjÄ…tkowo efektywny w przeszukiwaniu stanÃ³w kwantowych.\n2000 ZostaÅ‚ zbudowany pierwszy komputer kwantowy (5 qubitÃ³w) oparty na nuklearnym rezonansie magnetycznym, co stanowiÅ‚o waÅ¼ny krok w rozwoju fizycznych platform komputerÃ³w kwantowych.\n2001 Demonstracja algorytmu Shora potwierdziÅ‚a praktycznoÅ›Ä‡ i znaczenie algorytmÃ³w kwantowych.\n2007 Firma D-Wave dokonaÅ‚a pierwszej sprzedaÅ¼y komercyjnego komputera kwantowego, co miaÅ‚o wpÅ‚yw na rozwÃ³j technologii komputerÃ³w kwantowych w sektorze prywatnym.\nFirma IBM dokonaÅ‚a znaczÄ…cego przeÅ‚omu, pokazujÄ…c, Å¼e klasyczne superkomputery nie sÄ… w stanie efektywnie symulowaÄ‡ systemÃ³w zawierajÄ…cych wiÄ™cej niÅ¼ 56 kubitÃ³w, co jest znane jako â€œquantum supremacy.â€\n23 paÅºdziernika 2019: Google ogÅ‚osiÅ‚ uzyskanie tzw. quantum supremacy na 53 kubitach.\n2020 ZespÃ³Å‚ Jian-Wei Pana z University of Science and Technology of China dokonaÅ‚ przeÅ‚omu, realizujÄ…c 76 fotonowych kubitÃ³w na komputerze Jiuzhang.\n2023 Pierwszy logiczny qubit?\n2025 Google Quantum Echoes\n\nOd okoÅ‚o 1990 roku fizycy i informatycy pracujÄ… nad fizycznÄ… realizacjÄ… komputerÃ³w kwantowych. Jednym z popularnych modeli obliczeÅ„ na komputerach kwantowych jest model oparty na kwantowych obwodach (ang. quantum circuit), ktÃ³ry wykorzystuje qubity zamiast klasycznych bitÃ³w. Podobnie jak w przypadku obwodÃ³w klasycznych, w modelu kwantowym definiuje siÄ™ bramki kwantowe (ang. quantum gates), ktÃ³re pozwalajÄ… na wykonywanie operacji na qubitach.",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Wprowadzenie do obliczeÅ„ kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#dlaczego-chcemy-uÅ¼ywaÄ‡-komputerÃ³w-kwantowych",
    "href": "lectures/wyklad1.html#dlaczego-chcemy-uÅ¼ywaÄ‡-komputerÃ³w-kwantowych",
    "title": "Wprowadzenie do obliczeÅ„ kwantowych",
    "section": "Dlaczego chcemy uÅ¼ywaÄ‡ komputerÃ³w kwantowych?",
    "text": "Dlaczego chcemy uÅ¼ywaÄ‡ komputerÃ³w kwantowych?\n\nKwantowa zÅ‚oÅ¼onoÅ›Ä‡ (Quantum Complexity)\nNowy paradygmat wykorzystuje unikalne cechy interferencji, superpozycji i splÄ…tania w celu wykonywania obliczeÅ„.\nObecnie realizowany jest w trzech modelach:\n\nQuantum Circuits (Obwody Kwantowe) - oparty na modelu bramkowym, pozwala realizowaÄ‡ algorytmy typu QAOA, VQA, oraz metody hybrydowe.\nAdiabatyczne Obliczenia Kwantowe (D-Wave) - polegajÄ…ce na minimalizacji energii, z wykorzystaniem optymalizacji QUBO i analogii do modelu Isinga.\nTopologiczne Komputery Kwantowe - oparte na topologicznych kubitach.\n\nProblemy, ktÃ³re uwaÅ¼amy za trudne do rozwiÄ…zania klasycznie, takie jak optymalizacja, stajÄ… siÄ™ Å‚atwiejsze dla komputerÃ³w kwantowych. PrzykÅ‚adem moze byÄ‡ faktoryzacja liczb. Klasyczne komputery nie sÄ… w stanie efektywnie symulowaÄ‡ dziaÅ‚ania kwantowych komputerÃ³w. Koszt najlepszych symulatorÃ³w roÅ›nie wykÅ‚adniczo wraz z liczbÄ… kubitÃ³w. MoÅ¼liwoÅ›ci komputerÃ³w kwantowych sÄ… potencjalnie ogromne, ale obecnie istniejÄ… pewne ograniczenia link. Kwantowy komputer moÅ¼e byÄ‡ uÅ¼ywany do efektywnej symulacji niemal dowolnego procesu fizycznego zachodzÄ…cego w przyrodzie, choÄ‡ nie zawsze jesteÅ›my pewni, czy taka symulacja jest moÅ¼liwa.\nPodstawowym faktem przewagi komputerÃ³w kwantowych nad klasycznymi jest tzw. parallelizm. Ze wzglÄ™du, iÅ¼ kubity moga znajdowac siÄ™ w superpozycji stanÃ³w, komputer kwantowy moÅ¼e przeprowadzic obliczenia jednoczeÅ›nie na wszystkich stanach. Co dokÅ‚adnie to oznacza, poznamy w dalszej czesci wykÅ‚adu. RozwaÅ¼my sytuacjÄ™ w ktÃ³rej chcemy poznac dziaÅ‚anie funkcji \\(f(x)\\) dla pewnego argumentu \\(x\\) (dla pewnej liczby). Aby znaleÅºc wynik dla dwÃ³ch liczb (np. \\(x=0\\) i \\(x=1\\)) klasyczny komputer musi wykonac dwie operacje. Komputer kwantowy moÅ¼e uzuskac ten wynik przeprowadzajac obliczenia jednoczeÅ›nie dla obu waroÅ›ci. Do wykonania takiej operacji wystarczy jeden kubit. NastÄ™pnie jeÅ¼eli bÄ™dziemy chcieli obliczyc nasza funkcjÄ™ dla kolejnych liczb \\(x=2\\) (ktÃ³ra binarnie reprezentowana jest jako \\(10\\)) oraz liczby \\(x=3\\) (binarnie \\(11\\)) musimy dodac kolejny (jeden!) kubit. Dwa kubity moga posÅ‚uÅ¼yc do realizacji czterech rÃ³wnolegÅ‚ych operacji. JeÅ›li rozwaÅ¼ymy 3 kubity znowu mozemy podwoic iloÅ›c operacji (3 kubity maja 8 stanÃ³w bazowych). Dodanie kubitu do komputera kwantowego pozwala podwoic liczbÄ™ obliczeÅ„. W przypadku klasycznego komputera aby uzyskac taki efekt, potrzeba podwoic rownieÅ¼ liczbÄ™ bitÃ³w. n-kubitÃ³w moze realizowac \\(2^n\\) rÃ³wnolegÅ‚ych obliczeÅ„.\n\n\nKwantowa korekcja bÅ‚Ä™dÃ³w (Quantum Error Correction)\nDekoherencja, czyli oddziaÅ‚ywanie z otoczeniem, niszczy stan komputera kwantowego i wprowadza bÅ‚Ä™dy obliczeniowe. Istnieje potrzeba zabezpieczenia przed tym zjawiskiem. Obliczenia kwantowe wymagajÄ… tzw. korekcji bÅ‚Ä™dÃ³w, ktÃ³ra pomaga w utrzymaniu integralnoÅ›ci obliczeÅ„ na komputerach kwantowych. Aktualnie mÃ³wimy o erze Noisy Intermediate-Scale Quantum (NISQ), co oznacza, Å¼e komputery kwantowe wciÄ…Å¼ potrzebujÄ… rozwoju w zakresie korekcji bÅ‚Ä™dÃ³w i stabilnoÅ›ci.\n\n\nRealizacja fizyczna komputerÃ³w kwantowych\nprocesory kwantowe\n\n\n\nProces obliczeÅ„ kwantowych\nWykonanie obliczeÅ„ zwiÄ…zane jest z pojÄ™ciem fizycznego doÅ›wiadczenia. BÄ™dzie siÄ™ ono skÅ‚adaÄ‡ z trzech czÄ™Å›ci:\n\nprzygotowanie (przygotuj stan kwantowy kubitÃ³w),\newolucja (przeprowadÅº transformacjÄ™ za pomocÄ… bramek kwantowych),\npomiar i interpretacja wynikÃ³w.\n\n\nPodobnie w informatyce i w analizach danych wykonujemy obliczenia klasyczne. przygotowujemy dane (stan poczÄ…tkowy); nastÄ™pnie wykonujemy program (ewolucja) i odczytujemy wyniki (pomiar).\n\nNie obserwujemy tych etapÃ³w podczas codziennej interakcji z komputerem, wiÄ™c nie zauwaÅ¼amy w sposÃ³b Å›wiadomy powyÅ¼szego schematu dziaÅ‚ania. Piotr Gawron, Oscar SÅ‚owik - Rewolucja Stanu, Fantastyczne wprowadzenie do informatyki kwantowej.\n\nKaÅ¼dy komputer kwantowy (koprocesor) musi komunikowaÄ‡ siÄ™ z podukÅ‚adem klasycznym.",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Wprowadzenie do obliczeÅ„ kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#quantum-machine-learning",
    "href": "lectures/wyklad1.html#quantum-machine-learning",
    "title": "Wprowadzenie do obliczeÅ„ kwantowych",
    "section": "Quantum Machine Learning",
    "text": "Quantum Machine Learning\n\nKlasyczne dane w kwantowym uczeniu maszynowym\n\n\nCC - Classical data using classical computers, algorytmy inspirowane obliczeniami kwantowymi\nQC - Quantum data using classical (ML) computers. link1, link2, link3\nCQ - Classical data on qunatum computers. Na tym chcemy siÄ™ skupiÄ‡.\nQQ - Quantum data on quantum computers. Who knows?\n\n\n\nDostÄ™p do obliczeÅ„ kwantowych w chmurze\n\nIBM Quantum z wykorzystaniem biblioteki qiskit.\nPennylane z wykorzystaniem biblioteki pennylane.\nCirq Google z wykorzystaniem biblioteki cirq.\nD-Wave - Python\nXanadu - Pennylane Python library\nAmazon braket - AWS Python, Julia",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Wprowadzenie do obliczeÅ„ kwantowych"
    ]
  },
  {
    "objectID": "lectures/kodyw1.html",
    "href": "lectures/kodyw1.html",
    "title": "Modele uczenia maszynowego",
    "section": "",
    "text": "Do wygenerowania kodÃ³w uÅ¼yjemy biblioteki PyTorch",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Modele uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/kodyw1.html#regresja-liniowa",
    "href": "lectures/kodyw1.html#regresja-liniowa",
    "title": "Modele uczenia maszynowego",
    "section": "Regresja liniowa",
    "text": "Regresja liniowa\nWygenerujemy niezaszumione dane na podstawie wzoru \\(y = 2 x - 1\\). Na podstawie zbioru danych postaramy siÄ™ oszacowaÄ‡ nieznane parametry czyli wyraz przy \\(x\\) (\\(\\alpha_1 = 2\\)) i wyraz wolny (\\(\\alpha_0 = -1\\)).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# zbior danych\nx = range(11)\ny = [2*xi - 1 for xi in x]\nplt.plot(x, y, 'go', label='True data', alpha=0.5)\n\n\n\n\n\n\n\n\nModel regresji liniowej dla jednej zmiennej moÅ¼na zrealizowaÄ‡ jako prostÄ… jednowarstwowÄ… sieÄ‡ neuronowÄ…. CaÅ‚y proces moÅ¼na zrealizowaÄ‡ za pomocÄ… obiektu torch.nn.Linear\n\nimport torch\n\nclass LinearRegression(torch.nn.Module):\n\n    def __init__(self, inputSize, outputSize):\n        super(LinearRegression, self).__init__()\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(inputSize, outputSize)\n        ) \n        \n    def forward(self, x):\n        return self.layers(x)\n\n\nm = torch.nn.Linear(1,1)\n\n\nm\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nm.weight, m.bias\n\n(Parameter containing:\n tensor([[-0.1154]], requires_grad=True),\n Parameter containing:\n tensor([0.4927], requires_grad=True))\n\n\nAby nasze dane mogÅ‚ybyÄ‡ przeliczane przez bibliotekÄ™ PyTorch musimy je przetworzyÄ‡ na tensory - czyli obiekty z biblioteki PyTorch.\n\n# dostosowanie do pytorch\nx = np.array(x, dtype=np.float32)\ny = np.array(y, dtype=np.float32)\n\nX_train = torch.from_numpy(x).view(-1,1)\ny_train = torch.from_numpy(y).view(-1,1)\n\nUwaga - poniewaÅ¼ mamy jednÄ… zmiennÄ… zawierajÄ…cÄ… 10 przypadkÃ³w - potrzebujemy listy skÅ‚adajÄ…cej siÄ™ z 10 list jednoelementowych.\nMozna tez wykorzystac obiektowe programowanie.\n\nfrom torch.utils.data import Dataset, DataLoader\n\nclass LinearDataset(Dataset):\n    def __init__(self, X_train, y_train):\n        self.X_train = X_train # tensor typu torch\n        self.y_train = y_train\n\n    def __len__(self):\n        return len(self.y_train)\n\n    def __getitem__(self, idx):\n        return self.X_train[idx], self.y_train[idx]\n\n\ndataset = LinearDataset(X_train=X_train, y_train=y_train)\n\n\ndataloader = DataLoader(dataset, shuffle=True, batch_size=2)\n\nMoÅ¼emy utworzyÄ‡ model i wybraÄ‡ optymalizator z funkcjÄ… kosztu.\n\n# obiekt liniowej regresji w wersji sieci nn\nlr_model = LinearRegression(1,1)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(lr_model.parameters(), lr=0.01)\n\nMoÅ¼emy sprawdziÄ‡, Å¼e nasz model bÄ™dzie dostrajaÅ‚ 2 parametry.\n\nnum_params = sum(p.numel() for p in lr_model.parameters() if p.requires_grad)\nprint(f\"liczba trenowalnych parametrÃ³w: {num_params}\")\n\nliczba trenowalnych parametrÃ³w: 2\n\n\nParametry te w poczÄ…tkowej inicjalizacji majÄ… nastÄ™pujÄ…ce wartoÅ›ci:\n\nfor layer in lr_model.layers:\n    if isinstance(layer, torch.nn.Linear):\n        print(f\"weight: {layer.state_dict()['weight']}\")\n        print(f\"bias: {layer.state_dict()['bias']}\")\n\nweight: tensor([[0.7394]])\nbias: tensor([0.1832])\n\n\n\nepochs = 400\n# petla uczaca \nfor epoch in range(epochs):\n    lr_model.train() # etap trenowania \n\n    y_pred = lr_model(X_train)\n    loss = criterion(y_pred, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 50 == 0:\n        print(f'epoch: {epoch+1:03d}, loss = {loss.item():.4f}')\n \n    lr_model.eval() # etap ewaluacji modelu\n\n# po treningu jeszcze raz generujemy predykcje\nlr_model.eval()\nwith torch.no_grad():\n    predicted = lr_model(X_train)\n\nepoch: 050, loss = 0.2946\nepoch: 100, loss = 0.1681\nepoch: 150, loss = 0.0959\nepoch: 200, loss = 0.0547\nepoch: 250, loss = 0.0312\nepoch: 300, loss = 0.0178\nepoch: 350, loss = 0.0101\nepoch: 400, loss = 0.0058\n\n\nMozna tez wykorzystac obiekt dataloader\n\nfor epoch in range(50):\n    for X_batch, y_batch in dataloader:\n        preds = lr_model(X_batch)\n        loss = criterion(preds, y_batch)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    if epoch % 10 == 0:\n        print(f\"Epoch {epoch}, loss = {loss.item():.4f}\")\n\nEpoch 0, loss = 0.0060\nEpoch 10, loss = 0.0046\nEpoch 20, loss = 0.0000\nEpoch 30, loss = 0.0014\nEpoch 40, loss = 0.0001\n\n\nOtrzymane parametry po uczeniu\n\nprint(f\"po procesie uczenia waga: {lr_model.layers[0].weight} oraz bias {lr_model.layers[0].bias}\")\n\npo procesie uczenia waga: Parameter containing:\ntensor([[1.9952]], requires_grad=True) oraz bias Parameter containing:\ntensor([-0.9755], requires_grad=True)\n\n\nDopasowanie modelu do danych moÅ¼na przedstawiÄ‡ na wykresie\n\nplt.clf()\nplt.plot(X_train, y_train, 'go', label='True data', alpha=0.5)\nplt.plot(X_train, predicted, '--', label='Predictions', alpha=0.5)\nplt.legend(loc='best')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport torch\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\ntorch.manual_seed(1234)\n\n# DANE \nx = torch.linspace(0,10,500).view(-1,1)\ny = torch.sin(x)\ny = y + 0.1*(torch.rand(500).view(-1,1)-0.5)\n\nplt.figure(figsize=(8,4))\nplt.plot(x, torch.sin(x).view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\nplt.scatter(x,y, label=\"dane treningowe\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nclass SinusEstimator(torch.nn.Module):\n\n    def __init__(self, N_INPUT: int, N_OUTPUT: int):\n        super(SinusEstimator,self).__init__()\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(N_INPUT, 64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,32),\n            torch.nn.ReLU(),\n            torch.nn.Linear(32,16),\n            torch.nn.Tanh(),\n            torch.nn.Linear(16,N_OUTPUT)\n        )\n\n\n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nmodel = SinusEstimator(1,1)\n\nlearning_rate=0.001\noptimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\n\nlosses = []\n\n\ndef callback(model, loss):\n    losses.append(loss.item())\n\n    clear_output(wait=True)\n    prediction = model(x).detach()\n    plt.figure(figsize=(6,2.5))\n    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n    plt.plot(x[:,0].detach(), prediction[:,0], label=\"Classical solution\", color=\"tab:green\")\n    plt.title(f\"Training step {len(losses)}\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(6,2.5))\n    plt.title('Lossfn Visualised')\n    plt.plot(losses)\n    plt.show()\n\n\n\n\ndef train(X,Y, model, optimiser, epochs, lossfn, callback = None):\n    for epoch in range(epochs):\n        model.train()\n        prediction = model(X)\n        loss = lossfn(prediction, Y)\n\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        model.eval()\n        if callback != None:\n            callback(model, loss)\n\n\nx_train = x.requires_grad_(False)\n\ntrain(x_train, y, model, optimiser, 300, criterion, callback)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef mse(y, y_pred) -&gt; torch.Tensor:\n    return torch.mean((y-y_pred)**2)\n\ndef special_loss_fn(y, y_pred) -&gt; torch.Tensor:\n    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n\nmodel2 = SinusEstimator(1,1)\n\nlearning_rate=0.001\noptimiser = torch.optim.Adam(model2.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\nlosses = []\n\ntrain(x_train, y, model2, optimiser, 200, special_loss_fn, callback)",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Modele uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/kodyw1.html#regresja-logistyczna",
    "href": "lectures/kodyw1.html#regresja-logistyczna",
    "title": "Modele uczenia maszynowego",
    "section": "Regresja logistyczna",
    "text": "Regresja logistyczna\nW przypadku procesu klasyfikacji danych do numerycznego wyniku musimy dodaÄ‡ funkcjÄ™ aktywacji - sigmoid \\(\\sigma\\), ktÃ³ra pozwoli nam wygenerowaÄ‡ prawdopodobieÅ„stwo otrzymania klasy 1.\nDane wygenerujemy na podstawie pakietu scikit-learn\n\nfrom sklearn.datasets import make_classification\nimport numpy as np\n\n# prepare dataset\nX, y = make_classification(n_samples=10**4, n_features=10 ,random_state=42)\n\n\nimport torch\n\nclass LogisticRegression(torch.nn.Module):\n\n    def __init__(self, inputSize, outputSize):\n        super(LogisticRegression, self).__init__()\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(inputSize, outputSize),\n            torch.nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        logits = self.layers(x)\n        return logits\n\nPodobnie jak w przypadku regresji liniowej musimy przetworzyÄ‡ nasze dane do obiektÃ³w torch.\n\nX_train = torch.from_numpy(X.astype(np.float32))\ny_train = torch.from_numpy(y.astype(np.float32))\ny_train = y_train.view(y_train.shape[0], 1)\n\n\nmodel = LogisticRegression(X_train.shape[1], y_train.shape[1])\n\nlearningRate = 0.01\ncriterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n\n# petla uczaca \nnum_epochs = 500\n\nfor epoch in range(num_epochs):\n    # forward pass and loss\n    model.train()\n    y_predicted = model(X_train)\n    loss = criterion(y_predicted, y_train)\n    \n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    model.eval()\n\n    if (epoch+1) % 50 == 0:\n        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n\n\n\nmodel.eval()\nwith torch.no_grad():\n    y_predicted = model(X_train)  # no need to call model.forward()\n    y_predicted_cls = y_predicted.round()   # round off to nearest class\n    acc = y_predicted_cls.eq(y_train).sum() / float(y_train.shape[0])  # accuracy\n    print(f'accuracy = {acc:.4f}')\n    print(f\"predykcja dla wiersza 0:{y_predicted[0]}, wartosc prawdziwa: {y_train[0]}\")\n\nepoch: 50, loss = 0.6307\nepoch: 100, loss = 0.5104\nepoch: 150, loss = 0.4487\nepoch: 200, loss = 0.4120\nepoch: 250, loss = 0.3878\nepoch: 300, loss = 0.3708\nepoch: 350, loss = 0.3581\nepoch: 400, loss = 0.3484\nepoch: 450, loss = 0.3406\nepoch: 500, loss = 0.3343\naccuracy = 0.8830\npredykcja dla wiersza 0:tensor([0.8189]), wartosc prawdziwa: tensor([1.])",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "ZajÄ™cia",
      "Modele uczenia maszynowego"
    ]
  },
  {
    "objectID": "info.html",
    "href": "info.html",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3 -m venv &lt;name of env&gt;\n\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n\n(venv)$ \nJak uruchomiÄ‡ Å›rodowisko pythona w systemie Windows.\nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#python",
    "href": "info.html#python",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3 -m venv &lt;name of env&gt;\n\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n\n(venv)$ \nJak uruchomiÄ‡ Å›rodowisko pythona w systemie Windows.\nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "href": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z serwisu GitHub",
    "text": "Zacznij korzystaÄ‡ z serwisu GitHub\n\n\n\nTekst na podstawie strony jak korzystaÄ‡ z serwisu github\nPracujÄ…c nad projektem np. praca magisterska, (samodzielnie lub w zespole) czÄ™sto potrzebujesz sprawdziÄ‡ jakie zmiany, kiedy i przez kogo zostaÅ‚y wprowadzone do projektu. W zadaniu tym Å›wietnie sprawdza siÄ™ system kontroli wersji czyli GIT.\nGit moÅ¼esz pobraÄ‡ i zainstalowaÄ‡ jak zwykÅ‚y program na dowolnym komputerze. Jednak najczÄ™Å›ciej (maÅ‚e projekty) korzysta siÄ™ z serwisÃ³w z jakimÅ› systemem git. Jednym z najbardziej rozpoznawanych jest GitHub dziÄ™ki ktÃ³remu moÅ¼esz korzystaÄ‡ z systemu git bez jego instalacji na swoim komputerze.\nW darmowej wersji serwisu GitHub swoje pliki moÅ¼esz przechowywaÄ‡ w publicznych (dostÄ™p majÄ… wszyscy) repozytoriach.\nSkupimy siÄ™ wyÅ‚Ä…cznie na darmowej wersji serwisu GitHub.\ngit --version\n\nStruktura GitHuba\nNa najwyÅ¼szym poziomie znajdujÄ… siÄ™ konta indywidualne (np http://github.com/sebkaz, bÄ…dÅº zakÅ‚adane przez organizacje. UÅ¼ytkownicy indywidualni mogÄ… tworzyÄ‡ repozytoria publiczne (public ) bÄ…dÅº prywatne (private).\nJeden plik nie powinien przekraczaÄ‡ 100 MB.\nRepo (skrÃ³t do repozytorium) tworzymy za pomocÄ… Create a new repository. KaÅ¼de repo powinno mieÄ‡ swojÄ… indywidualnÄ… nazwÄ™.\n\n\nBranche\nGÅ‚Ã³wna (tworzona domyÅ›lnie) gaÅ‚Ä…Åº rapozytorium ma nazwÄ™ master.\n\n\nNajwaÅ¼niejsze polecnia do zapamiÄ™tania\n\nÅ›ciÄ…ganie repozytorium z sieci\n\ngit clone https://adres_repo.git\n\nW przypadku githuba moÅ¼esz pobraÄ‡ repozytorium jako plik zip.\n\n\nTworzenie repozytorium dla lokalnego katalogu\n\n# tworzenie nowego katalogu\nmkdir datamining\n# przejÅ›cie do katalogu\ncd datamining\n# inicjalizacja repozytorium w katalogu\ngit init\n# powinien pojawiÄ‡ siÄ™ ukryty katalog .git\n# dodajmy plik\necho \"Info \" &gt;&gt; README.md\n\nPoÅ‚Ä…cz lokalne repozytorium z kontem na githubie\n\ngit remote add origin https://github.com/&lt;twojGit&gt;/nazwa.git\n\nObsÅ‚uga w 3 krokach\n\n# sprawdÅº zmiany jakie zostaÅ‚y dokonane\ngit status\n# 1. dodaj wszystkie zmiany\ngit add .\n# 2. zapisz bierzÄ…cy stan wraz z informacjÄ… co zrobiÅ‚eÅ›\ngit commit -m \" opis \"\n# 3. potem juÅ¼ zostaje tylko\ngit push origin master\nWarto obejrzeÄ‡ Youtube course.\nCiekawe i proste wprowadzenie mozna znaleÅºÄ‡ tutaj"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "href": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z Dockera",
    "text": "Zacznij korzystaÄ‡ z Dockera\n\n\n\nW celu pobrania oprogramowania docker na swÃ³j system przejdÅº do strony.\nJeÅ¼li wszystko zainstalowaÅ‚o siÄ™ prawidÅ‚owo wykonaj nastÄ™pujÄ…ce polecenia:\n\nSprawdÅº zainstalowanÄ… wersjÄ™\n\ndocker --version\n\nÅšciÄ…gnij i uruchom obraz Hello World i\n\ndocker run hello-world\n\nPrzeglÄ…d Å›ciÄ…gnietych obrazÃ³w:\n\ndocker image ls\n\ndocker images\n\nPrzeglÄ…d uruchomionych kontenerÃ³w:\n\ndocker ps \n\ndocker ps -all\n\nZatrzymanie uruchomionego kontenera:\n\ndocker stop &lt;CONTAINER ID&gt;\n\nUsuniÄ™cie kontenera\n\ndocker rm -f &lt;CONTAINER ID&gt;\nPolecam rÃ³wnieÅ¼ krÃ³tkie intro"
  },
  {
    "objectID": "ksiazki.html",
    "href": "ksiazki.html",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "Chris Bernhardt, Obliczenia kwantowe dla kaÅ¼dego. PWN 2020\n\n\nWyjaÅ›nienie jak to dziaÅ‚a w obliczeniach kwantowych.\n\n\nMichel Le Bellac, WstÄ™p do informatyki kwantowej. PWN 2011\n\n\nTrudniejsza, duÅ¼o matematyki i fizyki.\n\n\nThomas G. Wong, Introduction to Classical and Quantum Computing. Rooted Grove 2022.\n\n\nBardzo dobra!, duÅ¼o przykÅ‚adÃ³w, duÅ¼o ciekawych informacji wyjaÅ›nianych bardzo szczegÃ³Å‚owo.\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage.\nP. Gawron, M. Cholewa, â€¦ Rewolucja stanu. Fantastyczne wprowadzenie do informatyki kwantowej. Quantumz.io 2021\nA. Saxena, J. Mancilla, I. Montalban, C. Pere, Financial Modeling Using Quantum Computing. Packt 2023\nM. Schuld, F. Petruccione, Machine Learning with Quantum Computers, Springer 2021.\n\n\n\n\n\n\n\nL. Moroney, Sztuczna inteligencja i uczenie maszynowe dla programistÃ³w. Praktyczny przewodnik po sztucznej inteligencji. Helion 2021. Zobacz opis lub Kup e-book\nBruce, Bruce, Gedeck, Statystyka praktyczna w data science. Wydanie II. Helion. 2021."
  },
  {
    "objectID": "ksiazki.html#ksiÄ…Å¼ki",
    "href": "ksiazki.html#ksiÄ…Å¼ki",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "Chris Bernhardt, Obliczenia kwantowe dla kaÅ¼dego. PWN 2020\n\n\nWyjaÅ›nienie jak to dziaÅ‚a w obliczeniach kwantowych.\n\n\nMichel Le Bellac, WstÄ™p do informatyki kwantowej. PWN 2011\n\n\nTrudniejsza, duÅ¼o matematyki i fizyki.\n\n\nThomas G. Wong, Introduction to Classical and Quantum Computing. Rooted Grove 2022.\n\n\nBardzo dobra!, duÅ¼o przykÅ‚adÃ³w, duÅ¼o ciekawych informacji wyjaÅ›nianych bardzo szczegÃ³Å‚owo.\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage.\nP. Gawron, M. Cholewa, â€¦ Rewolucja stanu. Fantastyczne wprowadzenie do informatyki kwantowej. Quantumz.io 2021\nA. Saxena, J. Mancilla, I. Montalban, C. Pere, Financial Modeling Using Quantum Computing. Packt 2023\nM. Schuld, F. Petruccione, Machine Learning with Quantum Computers, Springer 2021.\n\n\n\n\n\n\n\nL. Moroney, Sztuczna inteligencja i uczenie maszynowe dla programistÃ³w. Praktyczny przewodnik po sztucznej inteligencji. Helion 2021. Zobacz opis lub Kup e-book\nBruce, Bruce, Gedeck, Statystyka praktyczna w data science. Wydanie II. Helion. 2021."
  },
  {
    "objectID": "ksiazki.html#strony-www",
    "href": "ksiazki.html#strony-www",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "Strony WWW",
    "text": "Strony WWW\n\nPeter Shor WykÅ‚ad\n\n\nPakiety Python\n\nQiskit\nPennyLane\n\n\n\nPakiety Julia\n\nYao\nQAOA\n\n\n\nEdytory tekstu\n\nNotepad++\nSublime Text\nVisual Studio Code\n\n\n\nMarkdown\n\nMD\n\n\n\nFilmy\n\nWprowadzenie do obliczeÅ„ kwantowych\nQPoland, Bronze, Warsztaty z programowania komputerÃ³w kwantowych 2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Ciekawe ksiÄ…Å¼ki i strony internetowe zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki. JeÅ›li chciaÅ‚(a)byÅ› coÅ› dodaÄ‡ przeÅ›lij informacjÄ™ przez MS teams.",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "Informacje ogÃ³lne"
    ]
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Ciekawe ksiÄ…Å¼ki i strony internetowe zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki. JeÅ›li chciaÅ‚(a)byÅ› coÅ› dodaÄ‡ przeÅ›lij informacjÄ™ przez MS teams.",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "Informacje ogÃ³lne"
    ]
  },
  {
    "objectID": "index.html#kalendarz",
    "href": "index.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\n\n21.12.2025\n11.01.2025\n24.01.2025\n25.01.2025\n01.02.2026",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "Informacje ogÃ³lne"
    ]
  },
  {
    "objectID": "index.html#technologie",
    "href": "index.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nAlgebra liniowa - wektory, macierze, baza, iloczyn skalarny, iloczyn tensorowy\nPython, Jupyter notebook, Jupyter lab, Colab\nAlgorytmy sieci neuronowych i uczenia maszynowego w procesie klasyfikacji binarnej",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "Informacje ogÃ³lne"
    ]
  },
  {
    "objectID": "index.html#qpoland",
    "href": "index.html#qpoland",
    "title": "Informacje ogÃ³lne",
    "section": "QPoland",
    "text": "QPoland\nQPoland jest czeÅ›ciÄ… miÄ™dzynarodowej sieci QWorld.\nZapraszamy do wspÃ³lnego poszerzania wiedzy. SzczegÃ³Å‚y &gt; QWorld is a global network of individuals, groups, and communities collaborating on education and implementation of quantum technologies and research activities.",
    "crumbs": [
      "KsiÄ…Å¼ki",
      "Informacje ogÃ³lne"
    ]
  },
  {
    "objectID": "lectures/cwiczenia1.html",
    "href": "lectures/cwiczenia1.html",
    "title": "Pennylane wprowadzenie",
    "section": "",
    "text": "import torch\nimport matplotlib.pyplot as plt \nfrom IPython.display import clear_output\n\n\nx = torch.linspace(0,10,500).view(-1,1)\n\nsi = torch.sin(x).view(-1,1)\n\ny = si + 0.1*(torch.rand(500).view(-1,1)-0.5)\n\n\nplt.figure(figsize=(8,4))\nplt.plot(x, torch.sin(x).view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\nplt.scatter(x, y, label=\"dane treningowe\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\nclass QN(torch.nn.Module):\n    '''Classical -&gt; Quantum -&gt; Classical'''\n\n    def __init__(self, N_INPUT: int, N_OUTPUT: int, Q_NODE, N_QUBITS):\n        super().__init__()\n\n        self.layers = torch.nn.Sequential(\n            # input layer\n            torch.nn.Linear(N_INPUT, N_QUBITS),\n            # 1st hidden layer as a quantum circuit\n            Q_NODE,\n            # output layer\n            torch.nn.Linear(N_QUBITS, N_OUTPUT)\n        )\n        \n\n    def forward(self, x):\n        return  self.layers(x)\nimport pennylane as qml\n\nn_qubits = 3\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 3\n\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\nqmodel = QN(1, 1, qlayer, n_qubits)\n\nlearning_rate=1e-3\n\noptimiser = torch.optim.Adam(qmodel.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\n\nlosses = []\nx[:5], y[:5]\n\n(tensor([[0.0000],\n         [0.0200],\n         [0.0401],\n         [0.0601],\n         [0.0802]]),\n tensor([[ 0.0067],\n         [-0.0128],\n         [ 0.0702],\n         [ 0.0238],\n         [ 0.1135]]))\nqmodel.train()\nprediction = qmodel(x)\nprediction[:5]\n\ntensor([[-0.3303],\n        [-0.3310],\n        [-0.3316],\n        [-0.3323],\n        [-0.3329]], grad_fn=&lt;SliceBackward0&gt;)\ndef callback(model, loss):\n    losses.append(loss.item())\n\n    clear_output(wait=True)\n    prediction = model(x).detach()\n    plt.figure(figsize=(6,2.5))\n    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n    plt.plot(x[:,0].detach(), prediction[:,0], label=\"Classical solution\", color=\"tab:green\")\n    plt.title(f\"Training step {len(losses)}\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(6,2.5))\n    plt.title('Lossfn Visualised')\n    plt.plot(losses)\n    plt.show()\n\n\ndef train(X, Y, model, optimiser, epochs, lossfn, callback = None):\n    for _ in range(epochs):\n        model.train()\n        prediction = model(X)\n        loss = lossfn(prediction, Y)\n\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        model.eval()\n        if callback != None:\n            callback(model, loss)\ntrain(x, y, qmodel, optimiser,500, criterion, callback)"
  },
  {
    "objectID": "lectures/cwiczenia1.html#pennylane",
    "href": "lectures/cwiczenia1.html#pennylane",
    "title": "Pennylane wprowadzenie",
    "section": "ğŸ§  PennyLane",
    "text": "ğŸ§  PennyLane\nğŸ”— Strona oficjalna\nPennyLane to otwartoâ€‘ÅºrÃ³dÅ‚owa biblioteka Pythona opracowana przez Xanadu dla kwantowego uczenia maszynowego, obliczeÅ„ kwantowych oraz chemii kwantowej.\nZapewnia wysokopoziomowy, intuicyjny interfejs do budowania hybrydowych modeli kwantowoâ€‘klasycznych, Å‚Ä…czÄ…c obwody kwantowe z popularnymi frameworkami uczenia maszynowego, takimi jak PyTorch i TensorFlow.\nPennyLane wprowadza pojÄ™cie QNode (quantum node) â€“ funkcji kwantowych, ktÃ³re zachowujÄ… siÄ™ jak zwykÅ‚e funkcje Pythona i obsÅ‚ugujÄ… automatycznÄ… rÃ³Å¼niczkowanie (autodiff).\nUmoÅ¼liwia uruchamianie modeli zarÃ³wno na symulatorach, jak i na rzeczywistym sprzÄ™cie kwantowym (np. IBMâ€¯Q, Amazonâ€¯Braket i inne).\nDziÄ™ki PennyLane moÅ¼esz: - budowaÄ‡ wariacyjne algorytmy kwantowe,\n- trenowaÄ‡ kwantowe sieci neuronowe,\n- eksplorowaÄ‡ zaawansowane architektury kwantowego uczenia maszynowego.\nBiblioteka stanowi potÄ™Å¼ny most miÄ™dzy klasycznÄ… sztucznÄ… inteligencjÄ… a rosnÄ…cym Å›wiatem obliczeÅ„ kwantowych.\nPennyLane zawiera takÅ¼e spersonalizowanÄ… wersjÄ™ NumPy (pennylane.numpy), ktÃ³ra obsÅ‚uguje tablice Å›ledzone gradientem, co uÅ‚atwia integrowanie obwodÃ³w kwantowych w procesach optymalizacji."
  },
  {
    "objectID": "lectures/cwiczenia1.html#podstawowe-importy-bibliotek",
    "href": "lectures/cwiczenia1.html#podstawowe-importy-bibliotek",
    "title": "Pennylane wprowadzenie",
    "section": "podstawowe importy bibliotek",
    "text": "podstawowe importy bibliotek\n\nimport pennylane as qml\nimport pennylane.numpy as np\n\n\nğŸ§ª Obwody kwantowe w PennyLane\n\nObwody kwantowe sÄ… implementowane jako funkcje kwantowe, zwane takÅ¼e QNodeâ€™ami.\nSÄ… to funkcje kwantowe zachowujÄ…ce siÄ™ jak standardowe funkcje Pythona i wspierajÄ…ce automatycznÄ… rÃ³Å¼niczkacjÄ™ przy uÅ¼yciu klasycznych narzÄ™dzi ML.\nQNodeâ€™y sÄ… uruchamiane na rÃ³Å¼nych urzÄ…dzeniach (devices), takich jak:\n\nsymulatory (np. default.qubit, lightning.qubit) oraz,\nrzeczywisty sprzÄ™t kwantowy (np. IBMâ€¯Q, Amazonâ€¯Braket, Xanadu).\n\nUrzÄ…dzenia sÄ… wymienne i okreÅ›lajÄ…, w jaki sposÃ³b dana funkcja kwantowa jest wykonywana.\n\n\n\n\nPennyLane\n\n\nğŸ”— UrzÄ…dzenia, ktÃ³re moÅ¼esz uÅ¼ywaÄ‡\nMoÅ¼emy zdefiniowaÄ‡ nasz symulator â€” w tym przypadku uÅ¼yjemy default.qubit.\nMusimy takÅ¼e okreÅ›liÄ‡, ile kubitÃ³w chcemy uÅ¼yÄ‡, korzystajÄ…c z parametru wires.\nPrzykÅ‚adowe urzÄ…dzenia\n\ndefault.qubit â€“ symulator napisany w Pythonie\n\nlightning.qubit â€“ szybszy symulator napisany w C++\n\ndefault.mixed â€“ uÅ¼ywany do symulacji mieszanych stanÃ³w kwantowych\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n\n## for example \ndev2 = qml.device(\"default.qubit\", wires=3)\n\ndev3 = qml.device(\"lightning.qubit\", wires=['q1', 'aux'])\n\n\n\n\nkubity1\n\n\n\\[\n\\ket{000} = \\ket{0}\\otimes \\ket{0} \\otimes \\ket{0}\n\\]\n\nObiekt Qnode bÄ™dziemy uÅ¼ywaÄ‡ do definicji obwodÃ³w kwantowych. Obiekt ten wspiera wiele bibliotek do obliczeÅ„ numerycznych, tzw. interfejsÃ³w: - NumPy, - PyTorch, - TensorFlow, - JAX\nDomyÅ›lnie QNodes uÅ¼ywa interfejs NumPy. DziÄ™ki niemu mamy dostÄ™p do optymalizatorÃ³w domyÅ›lnych z biblioteki Pennylane. PozostaÅ‚e interferjsy wymagajÄ… uÅ¼ycia optymalizatorÃ³w z innych pakietÃ³w.\n\ndef qc(): # quantum circuit\n    return qml.state()\n\nwires oznacza kwantowy podsystem - czyli nasz pojedynczy kubit. Liczymy od 0 nie od 1.\n\nFunkcja kwantowa moÅ¼e pobieraÄ‡ klasyczne pamaretry\nFunkcja kwantowa moÅ¼e zawieraÄ‡ klasyczny flow (przepÅ‚yw) twojego programu for czy if else.\n\nZbiÃ³r kwantowych operatorÃ³w"
  },
  {
    "objectID": "lectures/cwiczenia1.html#uruchomienie-obwodu-kwantowego",
    "href": "lectures/cwiczenia1.html#uruchomienie-obwodu-kwantowego",
    "title": "Pennylane wprowadzenie",
    "section": "Uruchomienie obwodu kwantowego",
    "text": "Uruchomienie obwodu kwantowego\nUruchomienie odbywa siÄ™ po wyborze device z okreÅ›leniem iloÅ›ci kubitÃ³w (wires)\n\ncirc = qml.QNode(qc, dev)\ncirc()\n\narray([1.+0.j, 0.+0.j])\n\n\n\\[\n\\ket{\\psi} = \\ket{0} = [1,0]^{T}\n\\]\n\ncirc2 = qml.QNode(qc, dev2)\ncirc2()\n\narray([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j])\n\n\n\ncirc3 = qml.QNode(qc, dev3)\ncirc3()\n\narray([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j])\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\ndef quantum_circuit():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\ncirc = qml.QNode(quantum_circuit, dev)\n\ncirc()\n\narray([0.70710678+0.j, 0.70710678+0.j])\n\n\n\nfrom math import sqrt\nprint(circ()[0].real, 1/sqrt(2))\nprint(circ()[0].real == 1/sqrt(2))\n\n0.7071067811865475 0.7071067811865475\nTrue\n\n\n\nqml.draw(circ)()\n\n\nqml.draw_mpl(circ)()\n\nInna wersja\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqc()\n\narray([0.70710678+0.j, 0.70710678+0.j])\n\n\n\nimport matplotlib.pyplot as plt\n\nqml.drawer.use_style(\"pennylane_sketch\")\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\nMatplotlib is building the font cache; this may take a moment.\n\n\n\n\n\n\n\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.probs()\n\nqc()\n\narray([0.5, 0.5])\n\n\nDLa pustego obwodu\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    return qml.probs()\n\nresults = qc()\nresults\n\narray([1., 0.])\n\n\n\nuÅ¼yj qml.sample() lub qml.counts() dla innych wariantÃ³w wynikÃ³w.\n\nIloÅ›Ä‡ wykonaÅ„ obwodu sterowana jest w QNode za pomocÄ… parametru shot, ktÃ³ry moÅ¼e byÄ‡ liczbÄ… jak rÃ³wnieÅ¼ listÄ… liczb. &gt; Uwaga w wersji biblioteki &lt;0.43 - parametr shot ustawiany jest na poziomie device.\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev, shots=5)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.sample()\n\nqc()\n\narray([[1],\n       [0],\n       [0],\n       [0],\n       [1]])\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev, shots=100)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.counts()\n\nresults = qc()\n\n\nresults\n\n{np.str_('0'): np.int64(54), np.str_('1'): np.int64(46)}\n\n\nKod naszej wartwy ukrytej w ktÃ³rej uÅ¼yliÅ›my obwodu kwantowego realizowaÅ‚ nastÄ™pujÄ…ce obiekty i funkcje:\n\nimport pennylane as qml\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\nObwody kwantowe skÅ‚adajÄ… siÄ™ z rejestrÃ³w, ktÃ³re reprezentujÄ… poszczegÃ³lne kubity.\n\nDomyÅ›lnie kubity inicjalizujemy w stanie 0.\n\nOperacje wykonywane na kubitach nazywamy bramkami.\nOperacje te moÅ¼na wykonywaÄ‡ na jednym albo i wielu kubitach na raz.\nDomyÅ›lnie bÄ™dziemy optymalizowaÄ‡ algortymy aby skÅ‚adaÅ‚y siÄ™ z jak najmniejszej iloÅ›ci bramek dziaÅ‚ajÄ…cych na duÅ¼Ä… liczbÄ™ kubitÃ³w.\nGraficznie moÅ¼na rozumieÄ‡ realizacjÄ™ algorytmu jako stosowanie bramek na poszczegÃ³lnych kubitach.\n\n\n\nkibu2\n\n\nW bibliotece PennyLane, obwody kwantowe reprezentowane sÄ… przez kwantowe funkcje, realizowane przez klasyczne funkcje w pythonie.\nSchemat kodu penny lane moÅ¼emy zapisaÄ‡ jako:\nimport pennylane as qml\n\ndef my_quantum_function(params):\n\n    # Single-qubit operations with no input parameters\n    qml.Gate1(wires=0)\n    qml.Gate2(wires=2)\n\n     # Two-qubit operation with no input parameter on wires 0 and 1\n    qml.TwoQubitGate1(wires=[0, 1])\n\n    # A single-qubit operation with an input parameter\n    qml.Gate3(params[0], wires=2)\n\n\n    # Two-qubit operation with an input parameter on wires 0 and 1\n    qml.TwoQubitGate2(params[1], wires=[1, 2])\n    ... \n\n    # Return the result of a measurement\n    return qml.Measurement(wires=[0, 1])\nMatematycznie caÅ‚oÅ›Ä‡ moÅ¼emy zapisaÄ‡ jako:\n\nPrzykÅ‚adowo\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np\n\ndev = qml.device(\"default.qubit\", wires=2)\n#dev = qml.device(\"default.qubit\", wires=2, shots=1000)\n\n@qml.qnode(dev)\ndef circ(theta):\n    qml.Hadamard(wires = 0)\n    qml.CNOT(wires = [0,1])\n    qml.RZ(theta, wires = 0)\n    return qml.state()\n#    return qml.probs(wires = [0,1])\n\ncirc(np.pi)\n\narray([4.32978028e-17-0.70710678j, 0.00000000e+00+0.j        ,\n       0.00000000e+00+0.j        , 4.32978028e-17+0.70710678j])\n\n\n\nprint(qml.draw(circ)(np.pi))\n\n0: â”€â”€Hâ”€â•­â—â”€â”€RZ(3.14)â”€â”¤  State\n1: â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  State\n\n\n\nqml.draw_mpl(circ, decimals=2, style=\"sketch\", level=\"device\")(np.pi)\n\n\n\n\n\n\n\n\n\nBramka X\nBramka X-gate reprezentowana jest przez macierz Pauli-X :\n\\[\nX = \\begin{pmatrix}\n0 & 1 \\\\\n1 & 0 \\\\\n\\end{pmatrix}\n\\]\nBramka X obraca kubit w kierunku osi na sferze Blochâ€™a o \\(\\pi\\) radianÃ³w. Zmienia \\(|0\\rangle\\) na \\(|1\\rangle\\) oraz \\(|1\\rangle\\) na \\(|0\\rangle\\). Jest czÄ™sto nazywana kwantowym odpowiednikiem bramki NOT lub okreÅ›lana jako bit-flip.\n\\[ \\sigma_x \\ket{0} = \\ket{1} \\,\\,\\, \\sigma_x\\ket{1} = \\ket{0} \\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    return qml.state()\n\nqc()\n\narray([0.+0.j, 1.+0.j])\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    return qml.state()\n\nqc()\n\narray([0.+0.j, 1.+0.j])\n\n\n\nqml.draw_mpl(qc)()\n\n\n\n\n\n\n\n\n\n\nBramka Hadamarda\nBramka Hadamarda przetwarza stan \\(|0\\rangle\\) na kombinacje liniowa (superpozycje) \\(\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}}\\), co oznacza, Å¼e pomiar zwrÃ³ci z takim samym prawdopodobieÅ„stwem stanu 1 lub 0. Stan ten czÄ™sto oznaczany jest jako: \\(|+\\rangle\\).\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\n1 & -1 \\\\\n\\end{pmatrix}\n\\]\n\\[ H\\ket{0} = \\frac{\\sqrt{2}}{2} (\\ket{0}+ \\ket{1})\\] \\[ H\\ket{1} = \\frac{\\sqrt{2}}{2}(\\ket{0}- \\ket{1})\\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqc()\n\narray([0.70710678+0.j, 0.70710678+0.j])\n\n\nobwÃ³d z elementami pythona\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc(state):\n    if state==1:\n        qml.X(wires=0)\n    qml.Hadamard(wires=0)\n    qml.PauliX(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqc(0)\n\n\n\nbramka SX\nBramka SX jest pierwiastkiem kwadratowym bramki X. Dwukrotne zastosowanie powinno reazlizowac bramkÄ™ X.\n\\[\nSX = \\frac{1}{2}\\begin{pmatrix}\n1+i & 1-i \\\\\n1-i & 1+i \\\\\n\\end{pmatrix}\n\\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.SX(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\narray([0.5+0.5j, 0.5-0.5j])\n\n\n\n\n\n\n\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.SX(wires=0)\n    qml.SX(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\narray([0.+0.j, 1.+0.j])\n\n\n\n\n\n\n\n\n\n\n\nZ gate\n\\[\nZ = \\begin{pmatrix}\n1 & 0 \\\\\n0 & -1 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\pi} \\\\\n\\end{pmatrix}\n\\]\nInne nazwy bramki: phase flip lub sign flip\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.Z(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\narray([ 1.+0.j, -0.+0.j])\n\n\n\n\n\n\n\n\n\n\n\nRZ gate\nBramkÄ™ PauliZ moÅ¼na uogÃ³lniÄ‡ i sparametryzowaÄ‡ kÄ…tem. Dla \\(\\phi=\\pi\\) otrzymujemy bramkÄ™ \\(\\sigma_z\\).\n\\[\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\pi} \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\phi} \\\\\n\\end{pmatrix}\n\\]\n\\[ R_Z(\\phi) = e^{-i \\phi \\frac{\\sigma_z}{2} }  \\]\n\\[\nRZ = \\begin{pmatrix}\ne ^{-i \\frac{\\phi}{2} } & 0 \\\\\n0 & e ^{i \\frac{\\phi}{2} } \\\\\n\\end{pmatrix} = \\cos(\\frac{\\phi}{2})I_2 - \\sin(\\frac{\\phi}{2}) i\\sigma_z\n\\]\n\nfrom pennylane import numpy as np\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc(phi):\n    qml.RZ(phi=phi, wires=0)\n    return qml.state()\n\nqc(np.pi/2)\n\narray([0.70710678-0.70710678j, 0.        +0.j        ])\n\n\n\nqml.draw_mpl(qc)(np.pi/2)\n\n\n\n\n\n\n\n\n\n\nCNOT\nJednÄ… z bramek realizujÄ…cÄ… zadania na dwÃ³ch kubitach jest bramka CNOT, ktÃ³ra na bazie bitu kontrolnego decyduje czy zastosowaÄ‡ operacjÄ™ X do drugiego kubitu.\n\\[\n\\text{CNOT} = \\begin{bmatrix} 1 \\,\\, \\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\, \\,\\,\\, 1 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\,  0 \\,\\,\\,\\,\\, 1 \\\\ 0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\, 1\\,\\,\\,\\,\\, 0 \\end{bmatrix}\n\\]\n\\[ \\text{CNOT} \\ket{00} = \\ket{00} \\]\n\\[ \\text{CNOT} \\ket{10} = \\ket{11} \\]\n\nimport pennylane as qml\nimport pennylane.numpy as np\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circ(stan='0'):\n    if stan == '1':\n        qml.X(wires=0)\n    qml.CNOT(wires=[0,1])\n    # qml.CNOT(wires=[1,0])\n    return qml.state()\n\n\nstate = circ()\nprint(state)\n\n[1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n\n\n\nstate = circ('1')\nprint(state)\n\n[0.+0.j 0.+0.j 0.+0.j 1.+0.j]\n\n\nMagic ;)\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    # qml.Hadamard(wires=0)\n    qml.X(wires=0)\n    qml.CNOT(wires=[0,1])\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n/Users/seba/Documents/GitHub/technologiekwantowe/.venv/lib/python3.13/site-packages/pennylane/devices/device_api.py:193: PennyLaneDeprecationWarning: Setting shots on device is deprecated. Please use the `set_shots` transform on the respective QNode instead.\n  warnings.warn(\n\n\n{np.str_('11'): np.int64(100)}\n\n\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"sketch\")\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n/Users/seba/Documents/GitHub/technologiekwantowe/.venv/lib/python3.13/site-packages/pennylane/devices/device_api.py:193: PennyLaneDeprecationWarning: Setting shots on device is deprecated. Please use the `set_shots` transform on the respective QNode instead.\n  warnings.warn(\n\n\n{np.str_('01'): np.int64(51), np.str_('10'): np.int64(49)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n/Users/seba/Documents/GitHub/technologiekwantowe/.venv/lib/python3.13/site-packages/pennylane/devices/device_api.py:193: PennyLaneDeprecationWarning: Setting shots on device is deprecated. Please use the `set_shots` transform on the respective QNode instead.\n  warnings.warn(\n\n\n{np.str_('01'): np.int64(43), np.str_('10'): np.int64(57)}"
  },
  {
    "objectID": "lectures/cwiczenia1.html#zadanie---obwÃ³d-kwantowy-z-optymalizacjÄ…",
    "href": "lectures/cwiczenia1.html#zadanie---obwÃ³d-kwantowy-z-optymalizacjÄ…",
    "title": "Pennylane wprowadzenie",
    "section": "Zadanie - ObwÃ³d kwantowy z optymalizacjÄ…",
    "text": "Zadanie - ObwÃ³d kwantowy z optymalizacjÄ…\n\nNapisz nowy obwÃ³d kwantowy, ktÃ³ry zawieraÄ‡ bÄ™dzie tylko bramkÄ™ \\(R_X\\) dla dowolnego parametru \\(\\theta\\)\noblicz i uzasadnij, Å¼e wartoÅ›Ä‡ oczekiwana dla stanu \\(\\ket{\\psi} = R_X \\, \\ket{0}\\) \\[&lt;Z&gt; = cos^2(\\theta /2)- sin^2(\\theta /2) = cos(\\theta)\\]\n\nZaÅ‚Ã³Å¼my, Å¼e nasz problem obliczeniowy sprowadza siÄ™ do wygenerowania wartoÅ›ci oczekiwanej o wartoÅ›ci 0.5.\n\\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi} = 0.5\n\\]\nNapisz program znajdujÄ…cy rozwiÄ…zanie - szukajÄ…cy wagÄ™ \\(\\theta\\) dla naszego obwodu\n\nZdefiniuj funkcjÄ™ kosztu, ktÃ³rÄ… bedziemy minimalizowaÄ‡ \\((Y - y)^2\\)\nzainicjuj rozwiÄ…zanie \\(theta=0.01\\) i przypisz do tablicy array np.array(0.01, requires_grad=True)\nJako opt wybierz spadek po gradiencie : opt = qml.GradientDescentOptimizer(stepsize=0.1)\nuzyj poniÅ¼szego kodu do wygenerowania pÄ™tli obiczeÅ„\n\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef par_c(theta):\n    qml.RX(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\ndef cost_fn(theta):\n    return (par_c(theta) - 0.5)**2\n\ntheta = np.array(0.01, requires_grad=True)\n\nopt = qml.GradientDescentOptimizer(stepsize=0.1)\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={theta}, koszt: {cost_fn(theta)}\")\n\nepoka: 0, theta: 0.010999883335916642, koszt: 0.24993950555333252\nepoka: 10, theta: 0.028520883980330904, koszt: 0.2495934725570593\nepoka: 20, theta: 0.07380240366299132, koszt: 0.24728524869432472\nepoka: 30, theta: 0.18848123038996684, koszt: 0.23260358196368314\nepoka: 40, theta: 0.44553231822816797, koszt: 0.1619107886095973\nepoka: 50, theta: 0.7954652635692223, koszt: 0.03998102446252434\nepoka: 60, theta: 0.9838691671205075, koszt: 0.002894983645374295\nepoka: 70, theta: 1.0340365114010706, koszt: 0.00012891702079013002\nepoka: 80, theta: 1.0445781695789977, koszt: 5.138079127884816e-06\nepoka: 90, theta: 1.0466807535250837, koszt: 2.002500944777545e-07\nOptymalizacja zakonczona dla theta=1.0470778036429096, koszt: 1.0753863888581739e-08\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev, interface=\"torch\")\ndef par_c(theta):\n    qml.RX(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\n\ndef cost_fn(theta):\n    target = 0.5\n    return (par_c(theta) - target) ** 2\n\n\nimport torch\nfrom torch.optim import Adam \n\ntheta = torch.tensor(0.01, requires_grad=True)\n\noptimizer = Adam([theta], lr=0.1)\nepochs = 100\n\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    loss = cost_fn(theta)\n    loss.backward()\n    optimizer.step()\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nepoka: 0, theta: 0.1099998876452446, koszt: 0.24399264948886004\nepoka: 10, theta: 1.0454959869384766, koszt: 2.169397961785511e-06\nepoka: 20, theta: 1.0966185331344604, koszt: 0.0018829460500888265\nepoka: 30, theta: 0.9526112079620361, koszt: 0.006329338284936267\nepoka: 40, theta: 1.111649513244629, koszt: 0.0032281231974498922\nepoka: 50, theta: 1.0076401233673096, koszt: 0.0011463367423114523\nepoka: 60, theta: 1.0690317153930664, koszt: 0.00036201344599675586\nepoka: 70, theta: 1.0343401432037354, koszt: 0.000123060304852398\nepoka: 80, theta: 1.0549986362457275, koszt: 4.584717916214815e-05\nepoka: 90, theta: 1.042211651802063, koszt: 1.859027886217772e-05\n\n\nJeszcze jeden przykÅ‚ad\n\nNapisz obwÃ³d kwantowy, ktÃ³ry zawieraÄ‡ bÄ™dzie bramkÄ™ \\(R_X\\) dla parametru \\(\\theta_1\\) oraz \\(R_Y\\) dla parametru \\(\\theta_2\\)\noblicz i uzasadnij, Å¼e wartoÅ›Ä‡ oczekiwana dla stanu \\(\\ket{\\psi} = R_Y(\\theta_2) R_X(\\theta_1) \\, \\ket{0}\\)\n\n\\[&lt;Z&gt;  = \\cos(\\theta_1) \\cos(\\theta_2)\\]\nMozliwe wartoÅ›ci Å›redniej zawierajÄ… siÄ™ w przedziale \\(-1\\), \\(1\\).\nPrzyjmij zaÅ‚ozenie, ze optymalne rozwiÄ…zanie realizowane jest dla wartoÅ›ci oczekiwanej = 0.4\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef par_c(theta):\n    qml.RX(theta[0], wires=0)\n    qml.RY(theta[1], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\ndef cost_fn(theta):\n    return (par_c(theta) - 0.4)**2\n\ntheta = np.array([0.01, 0.02], requires_grad=True)\n\nopt = qml.GradientDescentOptimizer(stepsize=0.1)\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={theta}, koszt: {cost_fn(theta)}\")\n\nepoka: 0, theta: [0.01119924 0.02239872], koszt: 0.3596238551650218\nepoka: 10, theta: [0.03468299 0.06939827], koszt: 0.35640059384126277\nepoka: 20, theta: [0.10485556 0.21069384], koszt: 0.3277736421372642\nepoka: 30, theta: [0.26595847 0.55025891], koszt: 0.17843868824086426\nepoka: 40, theta: [0.41114867 0.91214351], koszt: 0.02593550926609833\nepoka: 50, theta: [0.45600131 1.05610411], koszt: 0.0017612620807984237\nepoka: 60, theta: [0.46619699 1.09390217], koszt: 0.00010074458607215528\nepoka: 70, theta: [0.4685347  1.10295946], koszt: 5.557697121461739e-06\nepoka: 80, theta: [0.469078   1.10508776], koszt: 3.040948516747214e-07\nepoka: 90, theta: [0.46920476 1.10558565], koszt: 1.6607272093790385e-08\nOptymalizacja zakonczona dla theta=[0.46923296 1.10569646], koszt: 1.2125189676042736e-09"
  },
  {
    "objectID": "lectures/cwiczenia1.html#klasyczne-dane",
    "href": "lectures/cwiczenia1.html#klasyczne-dane",
    "title": "Pennylane wprowadzenie",
    "section": "klasyczne dane",
    "text": "klasyczne dane\n\nimport pennylane as qml\nimport pennylane.numpy as np\n\n\nN = 3\nwires = range(N)\ndev = qml.device('default.qubit', wires)\n\n\n@qml.qnode(dev)\ndef basis_encoding(features):\n    qml.BasisEmbedding(features, wires)\n    return qml.probs()\n\n\nbasis_encoding([1,1,1])\n\narray([0., 0., 0., 0., 0., 0., 0., 1.])\n\n\n\\[ \\ket{111} = \\ket{1}\\otimes \\ket{1} \\otimes \\ket{1} = [0 0 0 0 0 0 0 1]^T\\]\n\nbasis_encoding(7)\n\narray([0., 0., 0., 0., 0., 0., 0., 1.])\n\n\n\nn_wires = 4 \ndev = qml.device('default.qubit', wires= n_wires)\n\n@qml.qnode(dev)\ndef circ(features):\n    for i in range(len(features)):\n        if features[i] == 1:\n            qml.X(i)\n    qml.Barrier()\n    qml.Hadamard(1)\n    qml.CNOT([1,3])\n    return qml.state()\n\n\ncirc([1,0,1,0])\n\narray([0.        +0.j, 0.        +0.j, 0.        +0.j, 0.        +0.j,\n       0.        +0.j, 0.        +0.j, 0.        +0.j, 0.        +0.j,\n       0.        +0.j, 0.        +0.j, 0.70710678+0.j, 0.        +0.j,\n       0.        +0.j, 0.        +0.j, 0.        +0.j, 0.70710678+0.j])\n\n\n\nqml.draw_mpl(circ, level='device', scale=0.7)([1,0,1,0])"
  },
  {
    "objectID": "lectures/cwiczenia1.html#amplitude-encoding",
    "href": "lectures/cwiczenia1.html#amplitude-encoding",
    "title": "Pennylane wprowadzenie",
    "section": "Amplitude encoding",
    "text": "Amplitude encoding\n\nimport pennylane as qml\nN = 3\nwires = range(N)\n\ndev = qml.device(\"default.qubit\", wires)\n\n@qml.qnode(dev)\ndef circuit(features):\n    qml.AmplitudeEmbedding(features, wires)\n    return qml.state()\n\n\ncircuit([0.625,0.0,0.0,0.0,0.625,0.375,0.25,0.125])\n\narray([0.625+0.j, 0.   +0.j, 0.   +0.j, 0.   +0.j, 0.625+0.j, 0.375+0.j,\n       0.25 +0.j, 0.125+0.j])\n\n\n\nimport pennylane as qml\nN = 3\nwires = range(N)\n\ndev = qml.device(\"default.qubit\", wires)\n\n@qml.qnode(dev)\ndef circuit(f=None):\n    qml.AmplitudeEmbedding(features=f, wires=dev.wires, normalize=True, pad_with=0)\n    return qml.expval(qml.PauliZ(0)), qml.state()\n\n\nvect = [0.1, -0.3, 0.5, 0.4, 0.2]\n\n\nnorm = np.linalg.norm(vect)\nnorm_vec = np.round([i / norm for i in vect], 4)\nprint(f\"Vec: {vect}, Norm{norm_vec}\")\n\nVec: [0.1, -0.3, 0.5, 0.4, 0.2], Norm[ 0.1348 -0.4045  0.6742  0.5394  0.2697]\n\n\n\nres, state = circuit(f=norm_vec)\nres2, state2 = circuit(f=vect)\n\n\nstate.real, state2.real\n\n(array([ 0.13479815, -0.40449446,  0.67419077,  0.53939262,  0.26969631,\n         0.        ,  0.        ,  0.        ]),\n array([ 0.13483997, -0.40451992,  0.67419986,  0.53935989,  0.26967994,\n         0.        ,  0.        ,  0.        ]))\n\n\n\nqml.draw_mpl(circuit)(norm_vec)\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nimport pennylane.numpy as np\nfrom sklearn.preprocessing import normalize\nfrom sklearn.datasets import load_wine\n\ndata = load_wine()\n\nX = data.data\ny = data.target\n\n\ndef prepare_ampl(x, target_len = 16):\n    padded = np.pad(x, (0, target_len - len(x)), mode=\"constant\")\n    normed = padded / np.linalg.norm(padded)\n    return np.array(normed, requires_grad=True)\n\n\nx0 = X[0]\nfeatures = prepare_ampl(x0)\n\n\nfeatures\n\ntensor([1.32644724e-02, 1.59397384e-03, 2.26512072e-03, 1.45415157e-02,\n        1.18382852e-01, 2.61001565e-03, 2.85237424e-03, 2.61001565e-04,\n        2.13461994e-03, 5.25731723e-03, 9.69434383e-04, 3.65402190e-03,\n        9.92738094e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], requires_grad=True)\n\n\n\nn_qubits = 4\ndev = qml.device('default.qubit', wires = n_qubits)\n\n@qml.qnode(dev)\ndef amplitude_circ(x):\n    qml.AmplitudeEmbedding(features=x, wires=range(n_qubits), normalize=False)\n    return qml.state()\n\n\nstate = amplitude_circ(features)\nstate\n\ntensor([1.32644724e-02+0.j, 1.59397384e-03+0.j, 2.26512072e-03+0.j,\n        1.45415157e-02+0.j, 1.18382852e-01+0.j, 2.61001565e-03+0.j,\n        2.85237424e-03+0.j, 2.61001565e-04+0.j, 2.13461994e-03+0.j,\n        5.25731723e-03+0.j, 9.69434383e-04+0.j, 3.65402190e-03+0.j,\n        9.92738094e-01+0.j, 0.00000000e+00+0.j, 0.00000000e+00+0.j,\n        0.00000000e+00+0.j], requires_grad=True)\n\n\n\n@qml.qnode(dev)\ndef amp_circ(x):\n    qml.AmplitudeEmbedding(features=x, wires=range(n_qubits), normalize=True, pad_with=0)\n    return qml.state()\n\n\nstate2 = amp_circ(X[0])\nstate2\n\narray([1.32644724e-02+0.j, 1.59397384e-03+0.j, 2.26512072e-03+0.j,\n       1.45415157e-02+0.j, 1.18382852e-01+0.j, 2.61001565e-03+0.j,\n       2.85237424e-03+0.j, 2.61001565e-04+0.j, 2.13461994e-03+0.j,\n       5.25731723e-03+0.j, 9.69434383e-04+0.j, 3.65402190e-03+0.j,\n       9.92738094e-01+0.j, 0.00000000e+00+0.j, 0.00000000e+00+0.j,\n       0.00000000e+00+0.j])"
  },
  {
    "objectID": "lectures/cwiczenia1.html#angle-encoding",
    "href": "lectures/cwiczenia1.html#angle-encoding",
    "title": "Pennylane wprowadzenie",
    "section": "Angle encoding",
    "text": "Angle encoding\n\\[ x \\to R_k(x) \\ket{0} = e^{-i\\,x \\frac{\\sigma_k}{2}} \\ket{0} \\]\n\nimport pennylane as qml\nimport pennylane.numpy as np\n\nfeatures= [np.pi/3, np.pi/4]\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circ(features):\n    qml.AngleEmbedding(features=features, rotation='Y', wires=range(2))\n    return qml.probs(wires=[0,1])\n\n\nnp.round(circ(features), 3)\n\ntensor([0.64 , 0.11 , 0.213, 0.037], requires_grad=True)\n\n\n\nqml.draw_mpl(circ)(features)\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nimport pennylane.numpy as np\nfrom sklearn.preprocessing import normalize\nfrom sklearn.datasets import load_wine\n\ndata = load_wine()\n\nX = data.data\ny = data.target\n\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, np.pi))\nX_scaled = scaler.fit_transform(X)\n\n\nX_scaled[0]\n\narray([2.64555171, 0.60224207, 1.7975958 , 0.80968883, 1.94642154,\n       1.97162022, 1.80277047, 0.88913   , 1.86315274, 1.16871536,\n       1.43031861, 3.04953133, 1.76350458])\n\n\n\ndev = qml.device('default.qubit', wires=13)\n\n@qml.qnode(dev)\ndef emb(x):\n    qml.AngleEmbedding(x, wires=range(len(x)), rotation='Y')\n    return qml.expval(qml.PauliZ(0))\n\n\nemb(X_scaled[0])\n\nnp.float64(-0.8794737512064895)\n\n\n\n@qml.qnode(dev)\ndef emb(x):\n    qml.AngleEmbedding(x, wires=range(len(x)), rotation='Y')\n    return [qml.expval(qml.PauliZ(i)) for i in range(len(x))]\n\n\nemb(X_saled[0])\n\n[np.float64(-0.8794737512064895),\n np.float64(0.8240675736145868),\n np.float64(-0.2248601123708277),\n np.float64(0.6897237772781044),\n np.float64(-0.3668542188130566),\n np.float64(-0.39017706326055457),\n np.float64(-0.2298992328822939),\n np.float64(0.6300878435817112),\n np.float64(-0.28820944852718955),\n np.float64(0.3913341989876884),\n np.float64(0.14001614496862924),\n np.float64(-0.9957653484788057),\n np.float64(-0.1915177132878786)]"
  },
  {
    "objectID": "lectures/cwiczenia1.html#kernel-trick",
    "href": "lectures/cwiczenia1.html#kernel-trick",
    "title": "Pennylane wprowadzenie",
    "section": "Kernel trick",
    "text": "Kernel trick\nDla prawdziwych danych trudno oczekiwaÄ‡ aby byÅ‚y one liniowo separowalne.\nDlatego jednym z rozwiÄ…zaÅ„ jest stworzenie odwzorowania do wyÅ¼ej wymiarowej przestrzeni tak by dane w niej byÅ‚y juÅ¼ liniowo separowalne. Obliczenie takiej transformacji dla dowolnych danych jest bardzo trudne, dlatego moÅ¼emy zastosowaÄ‡ tzw kernel trick. Potrzebujemy tylko obliczyÄ‡ iloczyn skalarny: \\[ K(x,x') = &lt;\\phi(x), \\phi(x')&gt;\\] bez jawnego wyznaczania \\(\\phi\\).\n\nx, xâ€™ wektory wejÅ›ciowe z oryginalnej przestrzeni\n\\(\\phi(x)\\) odwzorowanie do przestrzeni o wyÅ¼szym wymiarze\n\\(K(x, x')\\) funkcja jÄ…drowa - kernel function - oblicza iloczy skalarny w zadanej przestrzeni.\n\n\nLinear - \\(K(x, x') = x^{T}x'\\)\nPolynomial - \\(K(x,x') = (x^{T}x' +c)^d\\)\nRBF - \\(K(x,x') = exp(-\\gamma \\, |x-x'|^2)\\)\n\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_moons\nfrom sklearn.svm import SVC\n\nX,y = make_moons(n_samples=200, noise=0.2, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=44)\n\npoly_svm_clf = Pipeline([\n  #  ('polu_features', PolynomialFeatures(degree=3)),\n    ('scaler', StandardScaler()),\n    (\"linear_svc\", LinearSVC(C=1, loss='hinge'))\n])\n\npoly_svm_clf.fit(X_train, y_train)\n\nPipeline(steps=[('scaler', StandardScaler()),\n                ('linear_svc', LinearSVC(C=1, loss='hinge'))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\nsteps steps: list of tuples\n\nList of (name of step, estimator) tuples that are to be chained in\nsequential order. To be compatible with the scikit-learn API, all steps\nmust define `fit`. All non-last steps must also define `transform`. See\n:ref:`Combining Estimators ` for more details.\n[('scaler', ...), ('linear_svc', ...)]\n\n\n\ntransform_input transform_input: list of str, default=None\n\nThe names of the :term:`metadata` parameters that should be transformed by the\npipeline before passing it to the step consuming it.\n\nThis enables transforming some input arguments to ``fit`` (other than ``X``)\nto be transformed by the steps of the pipeline up to the step which requires\nthem. Requirement is defined via :ref:`metadata routing `.\nFor instance, this can be used to pass a validation set through the pipeline.\n\nYou can only set this if metadata routing is enabled, which you\ncan enable using ``sklearn.set_config(enable_metadata_routing=True)``.\n\n.. versionadded:: 1.6\nNone\n\n\n\nmemory memory: str or object with the joblib.Memory interface, default=None\n\nUsed to cache the fitted transformers of the pipeline. The last step\nwill never be cached, even if it is a transformer. By default, no\ncaching is performed. If a string is given, it is the path to the\ncaching directory. Enabling caching triggers a clone of the transformers\nbefore fitting. Therefore, the transformer instance given to the\npipeline cannot be inspected directly. Use the attribute ``named_steps``\nor ``steps`` to inspect estimators within the pipeline. Caching the\ntransformers is advantageous when fitting is time consuming. See\n:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`\nfor an example on how to enable caching.\nNone\n\n\n\nverbose verbose: bool, default=False\n\nIf True, the time elapsed while fitting each step will be printed as it\nis completed.\nFalse\n\n\n\n\n            \n        \n    StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\ncopy copy: bool, default=True\n\nIf False, try to avoid a copy and do inplace scaling instead.\nThis is not guaranteed to always work inplace; e.g. if the data is\nnot a NumPy array or scipy.sparse CSR matrix, a copy may still be\nreturned.\nTrue\n\n\n\nwith_mean with_mean: bool, default=True\n\nIf True, center the data before scaling.\nThis does not work (and will raise an exception) when attempted on\nsparse matrices, because centering them entails building a dense\nmatrix which in common use cases is likely to be too large to fit in\nmemory.\nTrue\n\n\n\nwith_std with_std: bool, default=True\n\nIf True, scale the data to unit variance (or equivalently,\nunit standard deviation).\nTrue\n\n\n\n\n            \n        \n    LinearSVC?Documentation for LinearSVC\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\npenalty penalty: {'l1', 'l2'}, default='l2'\n\nSpecifies the norm used in the penalization. The 'l2'\npenalty is the standard used in SVC. The 'l1' leads to ``coef_``\nvectors that are sparse.\n'l2'\n\n\n\nloss loss: {'hinge', 'squared_hinge'}, default='squared_hinge'\n\nSpecifies the loss function. 'hinge' is the standard SVM loss\n(used e.g. by the SVC class) while 'squared_hinge' is the\nsquare of the hinge loss. The combination of ``penalty='l1'``\nand ``loss='hinge'`` is not supported.\n'hinge'\n\n\n\ndual dual: \"auto\" or bool, default=\"auto\"\n\nSelect the algorithm to either solve the dual or primal\noptimization problem. Prefer dual=False when n_samples &gt; n_features.\n`dual=\"auto\"` will choose the value of the parameter automatically,\nbased on the values of `n_samples`, `n_features`, `loss`, `multi_class`\nand `penalty`. If `n_samples` &lt; `n_features` and optimizer supports\nchosen `loss`, `multi_class` and `penalty`, then dual will be set to True,\notherwise it will be set to False.\n\n.. versionchanged:: 1.3\nThe `\"auto\"` option is added in version 1.3 and will be the default\nin version 1.5.\n'auto'\n\n\n\ntol tol: float, default=1e-4\n\nTolerance for stopping criteria.\n0.0001\n\n\n\nC C: float, default=1.0\n\nRegularization parameter. The strength of the regularization is\ninversely proportional to C. Must be strictly positive.\nFor an intuitive visualization of the effects of scaling\nthe regularization parameter C, see\n:ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`.\n1\n\n\n\nmulti_class multi_class: {'ovr', 'crammer_singer'}, default='ovr'\n\nDetermines the multi-class strategy if `y` contains more than\ntwo classes.\n``\"ovr\"`` trains n_classes one-vs-rest classifiers, while\n``\"crammer_singer\"`` optimizes a joint objective over all classes.\nWhile `crammer_singer` is interesting from a theoretical perspective\nas it is consistent, it is seldom used in practice as it rarely leads\nto better accuracy and is more expensive to compute.\nIf ``\"crammer_singer\"`` is chosen, the options loss, penalty and dual\nwill be ignored.\n'ovr'\n\n\n\nfit_intercept fit_intercept: bool, default=True\n\nWhether or not to fit an intercept. If set to True, the feature vector\nis extended to include an intercept term: `[x_1, ..., x_n, 1]`, where\n1 corresponds to the intercept. If set to False, no intercept will be\nused in calculations (i.e. data is expected to be already centered).\nTrue\n\n\n\nintercept_scaling intercept_scaling: float, default=1.0\n\nWhen `fit_intercept` is True, the instance vector x becomes ``[x_1,\n..., x_n, intercept_scaling]``, i.e. a \"synthetic\" feature with a\nconstant value equal to `intercept_scaling` is appended to the instance\nvector. The intercept becomes intercept_scaling * synthetic feature\nweight. Note that liblinear internally penalizes the intercept,\ntreating it like any other term in the feature vector. To reduce the\nimpact of the regularization on the intercept, the `intercept_scaling`\nparameter can be set to a value greater than 1; the higher the value of\n`intercept_scaling`, the lower the impact of regularization on it.\nThen, the weights become `[w_x_1, ..., w_x_n,\nw_intercept*intercept_scaling]`, where `w_x_1, ..., w_x_n` represent\nthe feature weights and the intercept weight is scaled by\n`intercept_scaling`. This scaling allows the intercept term to have a\ndifferent regularization behavior compared to the other features.\n1\n\n\n\nclass_weight class_weight: dict or 'balanced', default=None\n\nSet the parameter C of class i to ``class_weight[i]*C`` for\nSVC. If not given, all classes are supposed to have\nweight one.\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``.\nNone\n\n\n\nverbose verbose: int, default=0\n\nEnable verbose output. Note that this setting takes advantage of a\nper-process runtime setting in liblinear that, if enabled, may not work\nproperly in a multithreaded context.\n0\n\n\n\nrandom_state random_state: int, RandomState instance or None, default=None\n\nControls the pseudo random number generation for shuffling the data for\nthe dual coordinate descent (if ``dual=True``). When ``dual=False`` the\nunderlying implementation of :class:`LinearSVC` is not random and\n``random_state`` has no effect on the results.\nPass an int for reproducible output across multiple function calls.\nSee :term:`Glossary `.\nNone\n\n\n\nmax_iter max_iter: int, default=1000\n\nThe maximum number of iterations to be run.\n1000\n\n\n\n\n            \n        \n    \n\n\n\nprint(f\"Test acc: {poly_svm_clf.score(X_test, y_test):.2f}\")\n\nTest acc: 0.82\n\n\n\nlinear_svm = SVC(kernel='linear', C=1)\nlinear_svm.fit(X_train, y_train)\ny_pred_linear = linear_svm.predict(X_test)\nacc_linear = accuracy_score(y_test, y_pred_linear)\n\n\nrbf_svm = SVC(kernel='rbf', C=1, gamma='scale')\nrbf_svm.fit(X_train, y_train)\ny_pred_rbf = rbf_svm.predict(X_test)\nacc_rbf = accuracy_score(y_test, y_pred_rbf)\n\n\ndef plot_decision_boundry(model, X, y, title):\n    h = 0.02\n    x_min, x_max = X[:, 0].min(), X[:, 0].max()+1\n    y_min, y_max = X[:, 1].min(), X[:, 1].max()+1\n\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n    plt.title(title)\n    plt.xlabel(\"Feature 1\")\n    plt.ylabel(\"Feature 2\")\n    plt.show()\n\n\nplot_decision_boundry(linear_svm, X_test, y_test, \"linear SVM\")\nplot_decision_boundry(rbf_svm, X_test, y_test, \"RBF SVM\")"
  },
  {
    "objectID": "lectures/cwiczenia1.html#idea-swap-testu",
    "href": "lectures/cwiczenia1.html#idea-swap-testu",
    "title": "Pennylane wprowadzenie",
    "section": "Idea swap testu",
    "text": "Idea swap testu\nSwap test sÅ‚uÅ¼y do obliczania wartoÅ›ci\n\\[ |\\langle \\psi |\\phi \\rangle |^2 \\]\nczyli kwadratu moduÅ‚u iloczynu skalarnego dwÃ³ch stanÃ³w kwantowych \\(|\\psi \\rangle\\) i \\(|\\phi \\rangle\\) .\n\nğŸ”§ ObwÃ³d swap testu\nSwap test uÅ¼ywa dodatkowego kubitu kontrolnego oraz bramki SWAP\nKontrolny kubit realizowany jest w stanie \\(|0\\rangle\\).\n\\[ \\ket{\\psi_0} = \\ket{0} \\otimes \\ket{\\psi} \\otimes \\ket{\\phi} \\]\n\n\nğŸ›ï¸ Jak to dziaÅ‚a\n\nZastosuj Hadamarda (zamiana bazy) na kontrolny (ancilla) kubit \\[ \\ket{\\psi_1} = (\\ket{0} + \\ket{1}) \\otimes \\ket{\\psi} \\otimes \\ket{\\phi} \\]\nZastosuj CSWAP (3 kubitowa bramka - controll = ancilla)\nZastosuj Hadamarda (powrÃ³t do bazy)\nPomiar ancilla kubitu.\n\nPrawdopodobieÅ„stwo, Å¼e kontrolny kubit da wynik \\(0\\), wynosi: \\[P(0)=\\frac{1+|\\langle \\psi |\\phi \\rangle |^2}{2}\\]\nPrawdopodobieÅ„stwo, Å¼e kontrolny kubit da wynik 1, wynosi: \\[P(1)=\\frac{1-|\\langle \\psi |\\phi \\rangle |^2}{2}\\]\nDziÄ™ki temu, mierzÄ…c kontrolny kubit, moÅ¼emy wyznaczyÄ‡ overlap miÄ™dzy stanami.\n\nimport pennylane as qml\nimport pennylane.numpy as np\n\ndev_test = qml.device('default.qubit', wires=['ancilla','phi','psi'], shots=5000)\n\n@qml.qnode(dev_test)\ndef swap_test():\n    qml.Hadamard(wires='ancilla')\n    \n    qml.X(wires=['phi'])\n    qml.Hadamard(wires=['psi'])\n\n    qml.CSWAP(wires=['ancilla', 'phi', 'psi'])\n    qml.Hadamard(wires='ancilla')\n    return qml.sample(wires='ancilla')\n\nres = swap_test()\n\nprint(f\"P(0) = {np.mean(res==0)}, P(1) = {np.mean(res == 1)}\")\nprint(f\"{2*np.mean(res==0) - 1}\")\n\nweryfikacja\n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef phi():\n    qml.X(wires=0)\n    return qml.state()\n\n@qml.qnode(dev)\ndef psi():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\ndef theory(phi, psi):\n    inner = np.vdot(phi, psi)\n    return float(np.abs(inner)**2)\n\ntheory(psi(), phi())"
  },
  {
    "objectID": "lectures/cwiczenia1.html#quantum-embedding",
    "href": "lectures/cwiczenia1.html#quantum-embedding",
    "title": "Pennylane wprowadzenie",
    "section": "Quantum Embedding",
    "text": "Quantum Embedding\nKwantowy Embedding reprezentuje klasyczne dane jako stan (wektor) w przestrzeni Hilberta. Odwzorowanie, ktÃ³re generuje embedding nazywamy quantum feature map.\nFeature map: \\(\\phi: X \\to F\\) gdzie \\(F\\) to nowa przestrzeÅ„ Hilberta stanÃ³w. \\[ x \\to \\ket{\\phi(x)} \\]\nW naszym przypadku to odwzorowanie realizujÄ… \\(U_{\\phi}(x)\\) macierze kodowania kÄ…towego. \\[ \\ket{0} \\to U_{\\phi}(x)\\ket{0} \\]\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, np.pi))\nX_scaled = scaler.fit_transform(X)\n\ny_scaled = 2 * y -1 \n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled)\n\nRozwaÅ¼my model kwantowy w postaci: \\[\nf(x) = \\braket{\\phi(x) | M | \\phi{x} }\n\\]\nModel moÅ¼e byÄ‡ realizowany jako wariacyjny obwÃ³d kwantowy.\nZamiast jednak trenowaÄ‡ parametry dla takiego obwodu moÅ¼emy wykorzystaÄ‡ kwantowy kernel ktÃ³ry realizuje siÄ™ przez SWAP test.\nZamiast SWAP testu moÅ¼emy wykorzystaÄ‡ inny obwÃ³d SzczegÃ³Å‚y tutaj\n\nfrom pennylane.templates import AngleEmbedding\n\n\nn_qubits = 2\ndev_kernel = qml.device('lightning.qubit', wires= n_qubits)\n\n\n\nprojector = np.zeros((2 ** n_qubits, 2 ** n_qubits))\nprojector[0, 0] = 1\n\n\n@qml.qnode(dev_kernel)\ndef kernel(x1, x2):\n    AngleEmbedding(x1, wires=range(n_qubits))\n    qml.adjoint(AngleEmbedding)(x2, wires=range(n_qubits))\n    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))\n\n\nimport pennylane.numpy as np \n\n\nX_train = np.array(X_train, requires_grad=False)\nX_test = np.array(X_test, requires_grad=False)\n\ny_train = np.array(y_train, requires_grad=False)\ny_test = np.array(y_test, requires_grad=False)\n\n\nkernel(X_train[0], X_train[0]), kernel(X_test[0], X_test[1])\n\n(array(1.), array(0.85153324))\n\n\n\ndef kernel_matrix(A, B):\n    return np.array([[kernel(a,b) for b in B] for a in A])\n\nsvm = SVC(kernel=kernel_matrix).fit(X_train, y_train)\n\n\npredictions = svm.predict(X_test)\n\n\nprint(f\"model qsvm {accuracy_score(predictions, y_test):.4f}\")\n\nmodel qsvm 0.8400\n\n\n\nsvm.predict(X_test[:4]), y_test[:4]\n\n(array([-1, -1, -1, -1]), tensor([-1, -1, -1, -1], requires_grad=False))"
  }
]